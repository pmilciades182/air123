# Airflow - Proyecto de Orquestaci√≥n de Tareas

Proyecto de Apache Airflow dockerizado para la ejecuci√≥n de tareas programadas. **Soporta m√∫ltiples instancias** en el mismo servidor.

## Descripci√≥n

Este proyecto implementa Apache Airflow 3.1.3 usando Docker, conectado a una base de datos PostgreSQL 14 para almacenar metadata. El proyecto est√° completamente parametrizado mediante variables de entorno, permitiendo ejecutar m√∫ltiples instancias independientes en el mismo servidor.

## Caracter√≠sticas

‚úÖ Apache Airflow 3.1.3 (√∫ltima versi√≥n estable)
‚úÖ Python 3.13
‚úÖ PostgreSQL 14 como base de datos de metadata
‚úÖ LocalExecutor para ejecuci√≥n de tareas
‚úÖ Soporte para m√∫ltiples instancias en el mismo servidor
‚úÖ Configuraci√≥n completamente parametrizable
‚úÖ Flujo de trabajo para edici√≥n local de DAGs

## Requisitos Previos

- Docker y Docker Compose instalados
- Acceso a PostgreSQL 14 (servidor: `192.168.24.109:5433`)
- Usuario y base de datos creados en PostgreSQL para cada instancia

## Estructura del Proyecto

```
airflow_develop/
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile              # Imagen personalizada de Airflow 3.1.3
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt        # Dependencias Python adicionales
‚îú‚îÄ‚îÄ dags_local/                 # DAGs editables localmente (versionado en Git)
‚îÇ   ‚îî‚îÄ‚îÄ ejemplo_dag.py          # DAG de ejemplo
‚îú‚îÄ‚îÄ dags/                       # DAGs desplegados (generado, NO versionado)
‚îú‚îÄ‚îÄ logs/                       # Logs de Airflow (generado autom√°ticamente)
‚îú‚îÄ‚îÄ plugins/                    # Plugins personalizados de Airflow
‚îú‚îÄ‚îÄ docker-compose.yml          # Configuraci√≥n de servicios Docker
‚îú‚îÄ‚îÄ Makefile                    # Comandos para gestionar el proyecto
‚îú‚îÄ‚îÄ .env                        # Variables de entorno de la instancia actual
‚îú‚îÄ‚îÄ .env.example                # Plantilla de configuraci√≥n
‚îú‚îÄ‚îÄ .env.instance2.example      # Ejemplo para segunda instancia
‚îú‚îÄ‚îÄ .gitignore                  # Archivos a ignorar en Git
‚îî‚îÄ‚îÄ README.md                   # Este archivo
```

## Configuraci√≥n de Variables de Entorno

El proyecto usa un archivo `.env` para toda la configuraci√≥n. Las variables principales son:

### Variables Obligatorias

| Variable | Descripci√≥n | Ejemplo |
|----------|-------------|---------|
| `PROJECT_NAME` | Nombre √∫nico de la instancia | `airflow1` |
| `POSTGRES_HOST` | Servidor PostgreSQL | `192.168.24.109` |
| `POSTGRES_PORT` | Puerto PostgreSQL | `5433` |
| `POSTGRES_DB` | Base de datos (√∫nica por instancia) | `airflow_db_instance1` |
| `POSTGRES_USER` | Usuario de BD (√∫nico por instancia) | `airflow_user_instance1` |
| `POSTGRES_PASSWORD` | Contrase√±a de BD | `airflow2025_instance1` |
| `AIRFLOW_WEBSERVER_PORT` | Puerto web (√∫nico por instancia) | `4000` |
| `AIRFLOW_FERNET_KEY` | Clave de encriptaci√≥n (√∫nica) | Generar con comando |
| `AIRFLOW_JWT_SECRET` | Secret JWT (√∫nico) | Generar con comando |
| `AIRFLOW_INTERNAL_API_SECRET` | Secret API interna (√∫nico) | String √∫nico |

### Generar Claves de Seguridad

```bash
# Generar AIRFLOW_FERNET_KEY
docker run --rm apache/airflow:3.1.3-python3.13 python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"

# Generar AIRFLOW_JWT_SECRET
openssl rand -base64 16
```

## Inicio R√°pido - Primera Instancia

### 1. Configurar Variables de Entorno

```bash
# Copiar el ejemplo y editar
cp .env.example .env
nano .env
```

Ajusta los valores en `.env`:
```bash
PROJECT_NAME=airflow1
POSTGRES_DB=airflow_db
POSTGRES_USER=airflow_user
POSTGRES_PASSWORD=airflow2025
AIRFLOW_WEBSERVER_PORT=4000
# ... generar y configurar las claves de seguridad
```

### 2. Crear Base de Datos en PostgreSQL

Con√©ctate a PostgreSQL y ejecuta:

```sql
CREATE USER airflow_user WITH PASSWORD 'airflow2025';
CREATE DATABASE airflow_db OWNER airflow_user;
GRANT ALL PRIVILEGES ON DATABASE airflow_db TO airflow_user;
```

### 3. Construir e Iniciar

```bash
make build
make start
```

### 4. Acceder a Airflow UI

Abre tu navegador en: http://localhost:4000

**Credenciales:**
- Usuario: `airflow`
- Contrase√±a: Ejecuta `make get-password` para obtenerla

### 5. Desplegar el DAG de Ejemplo

```bash
make deploy
```

## M√∫ltiples Instancias en el Mismo Servidor

El proyecto est√° dise√±ado para soportar m√∫ltiples instancias de Airflow corriendo simult√°neamente en el mismo servidor. Cada instancia es completamente independiente.

### Requisitos para M√∫ltiples Instancias

Cada instancia **DEBE** tener:
- ‚úÖ Un `PROJECT_NAME` √∫nico
- ‚úÖ Un puerto `AIRFLOW_WEBSERVER_PORT` √∫nico
- ‚úÖ Una base de datos PostgreSQL separada
- ‚úÖ Claves de seguridad √∫nicas (Fernet, JWT, Internal API)
- ‚úÖ Su propio directorio en el servidor

### Pasos para Crear una Segunda Instancia

#### 1. Copiar el Proyecto

```bash
# En el servidor, copia el proyecto a un nuevo directorio
cp -r /home/paxo/airflow_develop /home/paxo/airflow_develop_2
cd /home/paxo/airflow_develop_2
```

#### 2. Configurar el .env de la Segunda Instancia

```bash
# Usa el ejemplo de segunda instancia como base
cp .env.instance2.example .env
nano .env
```

Configura los valores √∫nicos:

```bash
PROJECT_NAME=airflow2
POSTGRES_DB=airflow_db_instance2
POSTGRES_USER=airflow_user_instance2
POSTGRES_PASSWORD=airflow2025_instance2
AIRFLOW_WEBSERVER_PORT=4001
```

**IMPORTANTE**: Genera **nuevas claves √∫nicas** para esta instancia:

```bash
# Generar nueva FERNET_KEY
docker run --rm apache/airflow:3.1.3-python3.13 python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"

# Generar nuevo JWT_SECRET
openssl rand -base64 16
```

#### 3. Crear Base de Datos en PostgreSQL

```sql
CREATE USER airflow_user_instance2 WITH PASSWORD 'airflow2025_instance2';
CREATE DATABASE airflow_db_instance2 OWNER airflow_user_instance2;
GRANT ALL PRIVILEGES ON DATABASE airflow_db_instance2 TO airflow_user_instance2;
```

#### 4. Construir e Iniciar la Segunda Instancia

```bash
cd /home/paxo/airflow_develop_2
make build
make start
```

#### 5. Acceder a las Instancias

- **Instancia 1**: http://localhost:4000
- **Instancia 2**: http://localhost:4001
- **Instancia 3**: http://localhost:4002 (si existe)

### Gestionar M√∫ltiples Instancias

Cada instancia se gestiona de forma independiente desde su propio directorio:

```bash
# Instancia 1
cd /home/paxo/airflow_develop
make status      # Ver estado de la instancia 1
make logs        # Ver logs de la instancia 1

# Instancia 2
cd /home/paxo/airflow_develop_2
make status      # Ver estado de la instancia 2
make logs        # Ver logs de la instancia 2
```

### Tabla de Referencia para M√∫ltiples Instancias

| Instancia | Directorio | PROJECT_NAME | Puerto | Base de Datos |
|-----------|-----------|--------------|--------|---------------|
| 1 | `/home/paxo/airflow_develop` | `airflow1` | 4000 | `airflow_db` |
| 2 | `/home/paxo/airflow_develop_2` | `airflow2` | 4001 | `airflow_db_instance2` |
| 3 | `/home/paxo/airflow_develop_3` | `airflow3` | 4002 | `airflow_db_instance3` |

## Comandos Disponibles (Makefile)

Todos los comandos se ejecutan dentro del directorio de la instancia correspondiente.

### Comandos Principales

```bash
# Ver ayuda (muestra la instancia actual)
make help

# Construir las im√°genes de Docker
make build

# Iniciar Airflow (webserver + scheduler + triggerer + dag-processor)
make start

# Detener todos los contenedores
make stop

# Reiniciar Airflow
make restart
```

### Comandos de Despliegue de DAGs

```bash
# Desplegar todos los DAGs de dags_local/ a dags/
make deploy

# Desplegar solo un archivo espec√≠fico
make deploy FILE=mi_dag.py
```

### Comandos de Monitoreo

```bash
# Ver logs de todos los servicios
make logs

# Ver logs solo del webserver
make logs-webserver

# Ver logs solo del scheduler
make logs-scheduler

# Ver estado de los contenedores
make status

# Obtener contrase√±a de acceso web
make get-password
```

### Comandos de Limpieza

```bash
# Limpiar contenedores y vol√∫menes
make clean
```

## Flujo de Trabajo para DAGs

### Por qu√© `dags_local/` y `dags/`?

- **`dags_local/`**: Archivos con permisos de tu usuario, editables en VSCode/IDE
- **`dags/`**: Carpeta montada en Docker (permisos de contenedor)

### Crear un Nuevo DAG

1. **Crear el archivo en `dags_local/`**:

```bash
# Opci√≥n 1: Copiar el ejemplo
cp dags_local/ejemplo_dag.py dags_local/mi_nuevo_dag.py

# Opci√≥n 2: Crear desde cero
nano dags_local/mi_nuevo_dag.py
```

2. **Editar el DAG en tu IDE favorito**

3. **Desplegar a Airflow**:

```bash
# Desplegar solo este archivo
make deploy FILE=mi_nuevo_dag.py

# O desplegar todos
make deploy
```

4. **Verificar en Airflow UI** - El DAG aparecer√° en ~30 segundos

### Editar un DAG Existente

1. Editar el archivo en `dags_local/`
2. Guardar cambios
3. Redesplegar: `make deploy FILE=mi_dag.py`
4. Airflow detectar√° los cambios autom√°ticamente

## Servicios Docker

El proyecto levanta los siguientes servicios:

- **airflow-webserver**: Interfaz web y API server (puerto configurable)
- **airflow-scheduler**: Programador de tareas
- **airflow-triggerer**: Gestor de tareas as√≠ncronas (requerido en Airflow 3.x)
- **airflow-dag-processor**: Procesador de DAGs (requerido en Airflow 3.x)
- **airflow-init**: Inicializaci√≥n y migraciones de BD (se ejecuta una vez)

## Soluci√≥n de Problemas

### Problema: Contenedores no inician

```bash
# Ver logs para identificar el error
make logs

# Verificar estado de contenedores
make status
```

### Problema: Conflicto de puertos

Si obtienes un error de puerto en uso:

1. Verifica qu√© est√° usando el puerto: `netstat -tuln | grep 4000`
2. Cambia `AIRFLOW_WEBSERVER_PORT` en `.env` a un puerto disponible
3. Reinicia: `make restart`

### Problema: DAGs no aparecen en la UI

1. Verifica que el archivo est√© en `dags/`: `ls -la dags/`
2. Revisa errores de sintaxis Python
3. Espera unos segundos (Airflow escanea cada 30 segundos)
4. Revisa los logs: `make logs-scheduler`

### Problema: Tareas fallan con "Invalid auth token"

Este error ocurre cuando las claves de seguridad no est√°n configuradas correctamente:

1. Aseg√∫rate de que `AIRFLOW_JWT_SECRET` est√© configurado en `.env`
2. Aseg√∫rate de que `AIRFLOW_FERNET_KEY` est√© configurado en `.env`
3. Reinicia los servicios: `make restart`

### Problema: No puedo conectar a PostgreSQL

Verifica:
1. El servidor PostgreSQL est√© accesible: `telnet 192.168.24.109 5433`
2. Las credenciales en `.env` sean correctas
3. El firewall permita la conexi√≥n al puerto 5433
4. El usuario y base de datos existan en PostgreSQL

### Problema: Conflicto entre instancias

Si dos instancias usan el mismo `PROJECT_NAME`:

1. Det√©n ambas instancias
2. Aseg√∫rate de que cada `.env` tenga un `PROJECT_NAME` √∫nico
3. Reinicia cada instancia desde su directorio

## Versiones

- **Apache Airflow**: 3.1.3
- **Python**: 3.13
- **PostgreSQL**: 14
- **Executor**: LocalExecutor

## Notas Importantes

- **DAGs**: Edita en `dags_local/` (versionado en Git), despliega con `make deploy`
- **Logs**: Se almacenan en la carpeta `logs/` (no versionado)
- **Plugins**: Los plugins personalizados van en `plugins/`
- **Credenciales**: El archivo `.env` NO debe versionarse en Git
- **Metadata**: Se almacena en PostgreSQL 14
- **Carpeta dags/**: NO versionada, se genera autom√°ticamente con `make deploy`
- **M√∫ltiples instancias**: Cada instancia DEBE tener su propio `PROJECT_NAME`, puerto, y base de datos

## Conexiones y DAGs de Ejemplo

Este proyecto incluye conexiones preconfiguradas y DAGs de ejemplo listos para usar:

### Conexiones Disponibles

- **SMTP** (`smtp_idesa`) - Env√≠o de correos electr√≥nicos
- **PostgreSQL** (`postgres_idesa`) - Base de datos planos
- **IBM i DB2** (`ibmi_dev`) - AS/400 con driver ODBC

### DAGs de Ejemplo

- `dag_email_manual.py` - Env√≠o de email de prueba
- `dag_postgres_test.py` - Consulta a tabla FRACCION en PostgreSQL
- `dag_ibmi_test.py` - Consulta a tabla ubitfra en IBM i DB2

**üìñ Ver documentaci√≥n completa:** [docs/](docs/)

## Documentaci√≥n

**üìö [DOCUMENTATION.md](DOCUMENTATION.md)** - √çndice visual completo de toda la documentaci√≥n

### Gu√≠as Principales

- **[üìñ docs/README.md](docs/README.md)** - √çndice detallado de documentaci√≥n t√©cnica
- **[üöÄ Installation Guide](docs/installation-guide.md)** - Configuraci√≥n inicial y setup
- **[üîå Connections Configuration](docs/connections-configuration.md)** - Configuraci√≥n de conexiones
- **[üìù DAG Development Guide](docs/dag-development-guide.md)** - Desarrollo de DAGs
- **[üîß IBM i ODBC Driver Setup](docs/ibmi-odbc-driver-setup.md)** - Setup del driver ODBC

### Recursos Externos

- [Documentaci√≥n oficial de Airflow 3.x](https://airflow.apache.org/docs/apache-airflow/3.1.3/)
- [Gu√≠a de DAGs](https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html)
- [Operadores disponibles](https://airflow.apache.org/docs/apache-airflow/stable/operators-and-hooks-ref.html)
- [Airflow 3.0 Migration Guide](https://airflow.apache.org/docs/apache-airflow/3.1.3/migrations-ref.html)

## Arquitectura de Airflow 3.x

Airflow 3.x introduce cambios arquitect√≥nicos significativos:

1. **API Server**: El webserver ahora usa `api-server` en lugar de `webserver`
2. **Execution API**: Nueva API para ejecuci√≥n de tareas que requiere autenticaci√≥n JWT
3. **DAG Processor**: Servicio separado para procesar archivos de DAGs
4. **Triggerer**: Servicio para manejar tareas as√≠ncronas (deferrable)
5. **Simple Auth Manager**: Nuevo sistema de autenticaci√≥n (reemplaza Flask-AppBuilder)

Todos estos componentes est√°n configurados y funcionando en este proyecto.
