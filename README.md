# Airflow - Proyecto de Orquestaci√≥n de Tareas

Proyecto de Apache Airflow dockerizado para la ejecuci√≥n de tareas programadas.

## Descripci√≥n

Este proyecto implementa Apache Airflow usando Docker, conectado a una base de datos PostgreSQL 14 para almacenar metadata. El webserver est√° configurado para ejecutarse en el puerto **4000**.

## Requisitos Previos

- Docker y Docker Compose instalados
- Acceso a PostgreSQL 14 (servidor: `192.168.24.109:5433`)
- Usuario y base de datos creados en PostgreSQL

## Configuraci√≥n de Base de Datos

### Credenciales PostgreSQL

**Servidor PostgreSQL 14:**
- Host: `192.168.24.109`
- Puerto: `5433`
- Base de datos: `airflow_db`
- Usuario Airflow: `airflow_user`
- Contrase√±a: `airflow2025`

**Credenciales Superusuario (solo para administraci√≥n):**
- Usuario: `postgres`
- Contrase√±a: `5PASzT0@iB`

### Usuario y Base de Datos ya creados

Ya se ejecutaron los siguientes comandos en PostgreSQL 14:

```sql
CREATE USER airflow_user WITH PASSWORD 'airflow2025';
CREATE DATABASE airflow_db OWNER airflow_user;
GRANT ALL PRIVILEGES ON DATABASE airflow_db TO airflow_user;
```

## Estructura del Proyecto

```
airflow_develop/
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile              # Imagen personalizada de Airflow
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt        # Dependencias Python adicionales
‚îú‚îÄ‚îÄ dags_local/                 # DAGs editables localmente (versionado en Git)
‚îÇ   ‚îî‚îÄ‚îÄ ejemplo_dag.py          # DAG de ejemplo
‚îú‚îÄ‚îÄ dags/                       # DAGs desplegados (generado, NO versionado)
‚îú‚îÄ‚îÄ logs/                       # Logs de Airflow (generado autom√°ticamente)
‚îú‚îÄ‚îÄ plugins/                    # Plugins personalizados de Airflow
‚îú‚îÄ‚îÄ docker-compose.yml          # Configuraci√≥n de servicios Docker
‚îú‚îÄ‚îÄ Makefile                    # Comandos para gestionar el proyecto
‚îú‚îÄ‚îÄ .env                        # Variables de entorno (NO versionar)
‚îú‚îÄ‚îÄ .gitignore                  # Archivos a ignorar en Git
‚îî‚îÄ‚îÄ README.md                   # Este archivo
```

## Comandos Disponibles (Makefile)

### Comandos Principales

```bash
# Ver ayuda
make help

# Construir las im√°genes de Docker
make build

# Iniciar Airflow (webserver + scheduler)
make start

# Detener todos los contenedores
make stop

# Reiniciar Airflow
make restart
```

### Comandos de Despliegue de DAGs

```bash
# Desplegar todos los DAGs de dags_local/ a dags/
make deploy

# Desplegar solo un archivo espec√≠fico
make deploy FILE=mi_dag.py
```

### Comandos Adicionales

```bash
# Ver logs de todos los servicios
make logs

# Ver logs solo del webserver
make logs-webserver

# Ver logs solo del scheduler
make logs-scheduler

# Ver estado de los contenedores
make status

# Limpiar contenedores y vol√∫menes
make clean

# Inicializar estructura de carpetas
make init
```

## Inicio R√°pido

### 1. Primera vez - Construir e Iniciar

```bash
make build
make start
```

### 2. Desplegar el DAG de ejemplo

```bash
make deploy
```

Esto copiar√° todos los DAGs de `dags_local/` a `dags/` donde Airflow los detectar√° autom√°ticamente.

### 3. Acceder a Airflow UI

Abre tu navegador en: http://localhost:4000

**Credenciales de acceso:**
- Usuario: `airflow`
- Contrase√±a: `airflow`

### 4. Verificar el DAG de ejemplo

En la interfaz de Airflow ver√°s el DAG `ejemplo_dag` que:
- Se ejecuta diariamente a las 8:00 AM
- Contiene 4 tareas de ejemplo
- Muestra un flujo b√°sico de trabajo

## Flujo de Trabajo para Crear y Editar DAGs

### üìù Los DAGs se editan en `dags_local/` y se despliegan a `dags/`

**¬øPor qu√© este flujo?**
- `dags_local/`: Archivos con permisos de tu usuario, editables en VSCode
- `dags/`: Carpeta montada en Docker (permisos de contenedor)

### Crear un Nuevo DAG

1. **Crear el archivo en `dags_local/`** (editable en VSCode):

```bash
# Opci√≥n 1: Copiar el ejemplo
cp dags_local/ejemplo_dag.py dags_local/mi_nuevo_dag.py

# Opci√≥n 2: Crear desde cero
nano dags_local/mi_nuevo_dag.py  # o usar VSCode
```

2. **Editar el DAG** en VSCode con tus permisos locales

Ejemplo m√≠nimo:

```python
from datetime import datetime
from airflow import DAG
from airflow.operators.python import PythonOperator

def mi_funcion():
    print("Hola desde Airflow!")

with DAG(
    'mi_dag',
    start_date=datetime(2025, 1, 1),
    schedule_interval='@daily',
    catchup=False,
) as dag:

    tarea = PythonOperator(
        task_id='mi_tarea',
        python_callable=mi_funcion,
    )
```

3. **Desplegar a Airflow**:

```bash
# Desplegar todos los DAGs
make deploy

# O solo el archivo espec√≠fico
make deploy FILE=mi_nuevo_dag.py
```

4. **Verificar en Airflow UI** (http://localhost:4000)
   - El DAG aparecer√° en ~30 segundos

### Editar un DAG Existente

1. Editar el archivo en `dags_local/` con VSCode
2. Guardar cambios
3. Redesplegar:
   ```bash
   make deploy FILE=mi_dag.py
   ```
4. Airflow detectar√° los cambios autom√°ticamente

## Servicios Docker

El proyecto levanta los siguientes servicios:

- **airflow-webserver**: Interfaz web (puerto 4000)
- **airflow-scheduler**: Programador de tareas
- **airflow-init**: Inicializaci√≥n y migraciones de BD

## Gesti√≥n del Proyecto

### Detener Airflow

```bash
make stop
```

### Ver logs en tiempo real

```bash
make logs
```

### Limpiar completamente (incluye vol√∫menes)

```bash
make clean
```

### Reconstruir despu√©s de cambios en Dockerfile

```bash
make build
make restart
```

## Notas Importantes

- **DAGs**: Edita en `dags_local/` (versionado en Git), despliega con `make deploy`
- **Logs**: Se almacenan en la carpeta `logs/` (no versionado)
- **Plugins**: Los plugins personalizados van en `plugins/`
- **Credenciales**: El archivo `.env` NO debe versionarse en Git
- **Metadata**: Se almacena en PostgreSQL 14 (servidor empresa)
- **Carpeta dags/**: NO versionada, se genera autom√°ticamente con `make deploy`

## Soluci√≥n de Problemas

### Airflow no inicia

```bash
# Ver logs para identificar el error
make logs

# Verificar estado de contenedores
make status
```

### Problemas de conexi√≥n a PostgreSQL

Verifica que:
1. El servidor PostgreSQL est√© accesible: `192.168.24.109:5433`
2. Las credenciales en `.env` sean correctas
3. El firewall permita la conexi√≥n al puerto 5433

### DAGs no aparecen en la UI

1. Verifica que el archivo est√© en la carpeta `dags/`
2. Revisa que no tenga errores de sintaxis Python
3. Espera unos segundos (Airflow escanea cada 30 segundos)
4. Revisa los logs: `make logs-scheduler`

## Versiones

- Apache Airflow: 2.10.4
- Python: 3.11
- PostgreSQL: 14
- Executor: LocalExecutor

## Documentaci√≥n Adicional

- [Documentaci√≥n oficial de Airflow](https://airflow.apache.org/docs/)
- [Gu√≠a de DAGs](https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html)
- [Operadores disponibles](https://airflow.apache.org/docs/apache-airflow/stable/operators-and-hooks-ref.html)
