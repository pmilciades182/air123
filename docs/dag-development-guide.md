# DAGs de Airflow - Carpeta Local

Esta carpeta contiene los archivos de DAGs que se editan localmente y luego se despliegan a Airflow.

## üîß Configuraci√≥n R√°pida para VS Code

Si VS Code no reconoce las importaciones de Airflow (`Import "airflow..." could not be resolved`), ejecuta:

```bash
make setup-local
```

Este comando:
- ‚úÖ Crea un entorno virtual Python local (`.venv`)
- ‚úÖ Instala todas las dependencias de Airflow
- ‚úÖ Configura VS Code autom√°ticamente

Luego recarga VS Code y selecciona el int√©rprete `.venv/bin/python`.

**Nota:** El entorno `.venv` es SOLO para IntelliSense de VS Code. Airflow sigue ejecut√°ndose en Docker.

## üìÇ Estructura

```
dags_local/
‚îú‚îÄ‚îÄ README.md                 # Este archivo
‚îú‚îÄ‚îÄ ejemplo_dag.py           # DAG de ejemplo b√°sico con tareas Python y Bash
‚îú‚îÄ‚îÄ dag_email_manual.py      # DAG para env√≠o de emails (solo manual)
‚îú‚îÄ‚îÄ dag_postgres_test.py     # DAG para consultas PostgreSQL (solo manual)
‚îî‚îÄ‚îÄ dag_ibmi_test.py         # DAG para consultas IBM i DB2 (solo manual)
```

## üöÄ Flujo de Trabajo

### 1. Editar DAGs en esta carpeta

Crea o edita archivos `.py` en `dags_local/` usando tu editor favorito.

### 2. Desplegar a Airflow

```bash
# Desplegar un DAG espec√≠fico
make deploy FILE=mi_dag.py

# Desplegar todos los DAGs
make deploy
```

### 3. Verificar en Airflow UI

Los DAGs aparecer√°n en la UI de Airflow en ~30 segundos despu√©s del deploy.

## üìã DAGs Disponibles

### ejemplo_dag.py

**Descripci√≥n:** DAG de ejemplo b√°sico que demuestra tareas Python y Bash.

- **Schedule:** Diario a las 8:00 AM
- **Tags:** ejemplo, tutorial
- **Tareas:**
  - Tarea de inicio
  - Verificaci√≥n del sistema (Bash)
  - Procesamiento de datos
  - Finalizaci√≥n

### dag_email_manual.py

**Descripci√≥n:** Env√≠a un correo electr√≥nico de prueba usando SMTP.

- **Schedule:** Manual (solo se ejecuta al hacer trigger manual)
- **Tags:** email, manual
- **Conexi√≥n:** smtp_idesa
- **Tareas:**
  - Log de ejecuci√≥n manual
  - Verificaci√≥n de conectividad SMTP
  - Env√≠o de email

**Destinatario:** pablo.gonzalez@idesa.com.py

### dag_postgres_test.py

**Descripci√≥n:** Consulta la tabla FRACCION en PostgreSQL.

- **Schedule:** Manual (solo se ejecuta al hacer trigger manual)
- **Tags:** postgres, test, manual
- **Conexi√≥n:** postgres_idesa
- **Tareas:**
  - Verificaci√≥n de conexi√≥n PostgreSQL
  - Consulta a tabla FRACCION
  - Resumen de ejecuci√≥n

**SQL:**
```sql
SELECT nfrac, centro_f, fecha, hora, usuario, estado
FROM public."FRACCION"
LIMIT 10;
```

### dag_ibmi_test.py

**Descripci√≥n:** Consulta la tabla ubitfra en IBM i DB2 (AS/400).

- **Schedule:** Manual (solo se ejecuta al hacer trigger manual)
- **Tags:** ibmi, db2, as400, test, manual
- **Conexi√≥n:** ibmi_dev
- **Tareas:**
  - Verificaci√≥n de drivers ODBC
  - Verificaci√≥n de conexi√≥n IBM i
  - Consulta a tabla ubitfra
  - Resumen de ejecuci√≥n

**SQL:**
```sql
SELECT * FROM gxdbprueba.ubitfra
FETCH FIRST 10 ROWS ONLY
```

## ‚úèÔ∏è Crear un Nuevo DAG

### 1. Crear el archivo

```bash
# Copiar un ejemplo existente
cp dags_local/ejemplo_dag.py dags_local/mi_nuevo_dag.py

# O crear desde cero
nano dags_local/mi_nuevo_dag.py
```

### 2. Estructura b√°sica de un DAG

```python
from datetime import datetime
from airflow import DAG
from airflow.providers.standard.operators.python import PythonOperator

# Argumentos por defecto
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
}

# Funci√≥n de ejemplo
def mi_funcion():
    print("Hola desde Airflow!")

# Definici√≥n del DAG
with DAG(
    'mi_nuevo_dag',
    default_args=default_args,
    description='Descripci√≥n de mi DAG',
    schedule='0 8 * * *',  # Cron expression o None para manual
    start_date=datetime(2025, 1, 1),
    catchup=False,
    tags=['mi_tag'],
) as dag:

    tarea1 = PythonOperator(
        task_id='mi_tarea',
        python_callable=mi_funcion,
    )
```

### 3. Desplegar

```bash
make deploy FILE=mi_nuevo_dag.py
```

## üîó Usar Conexiones

Todas las conexiones est√°n preconfiguradas mediante variables de entorno.

### SMTP

```python
from airflow.providers.smtp.operators.smtp import EmailOperator

enviar = EmailOperator(
    task_id='enviar_email',
    to='destinatario@example.com',
    subject='Asunto',
    html_content='<p>Contenido</p>',
    conn_id='smtp_idesa',
)
```

### PostgreSQL

```python
from airflow.providers.postgres.hooks.postgres import PostgresHook

def consultar():
    hook = PostgresHook(postgres_conn_id='postgres_idesa')
    records = hook.get_records("SELECT * FROM tabla")
    for record in records:
        print(record)
```

### IBM i DB2

```python
import pyodbc

def consultar():
    conn_string = (
        "DRIVER={iSeries Access ODBC Driver};"
        "SYSTEM=192.168.24.1;"
        "UID=WEBUSR;"
        "PWD=idesa18;"
    )
    conn = pyodbc.connect(conn_string)
    cursor = conn.cursor()
    cursor.execute("SELECT * FROM biblioteca.tabla")
    # ... procesar resultados
```

## üìÖ Configurar Schedule

### Ejecuci√≥n Manual (Sin Schedule)

```python
schedule=None
```

### Cron Expressions

```python
# Diario a las 8:00 AM
schedule='0 8 * * *'

# Cada hora
schedule='0 * * * *'

# Lunes a Viernes a las 9:00 AM
schedule='0 9 * * 1-5'

# Cada 15 minutos
schedule='*/15 * * * *'

# Primer d√≠a del mes a las 00:00
schedule='0 0 1 * *'
```

### Presets de Airflow

```python
from airflow.timetables.datasets import DatasetOrTimeSchedule

# Diario
schedule='@daily'

# Por hora
schedule='@hourly'

# Semanal
schedule='@weekly'

# Mensual
schedule='@monthly'
```

## üè∑Ô∏è Tags Recomendados

Usa tags para organizar tus DAGs:

```python
tags=['produccion', 'etl', 'diario']
tags=['desarrollo', 'test', 'manual']
tags=['reportes', 'mensual']
tags=['integracion', 'api', 'tiempo_real']
```

## üìñ Documentaci√≥n Completa

Para m√°s informaci√≥n sobre conexiones, configuraci√≥n y troubleshooting, consulta:

- **[CONEXIONES_Y_DAGS.md](../CONEXIONES_Y_DAGS.md)** - Documentaci√≥n completa de conexiones
- **[README.md](../README.md)** - Documentaci√≥n general del proyecto
- **[README_SETUP.md](../README_SETUP.md)** - Gu√≠a de configuraci√≥n

## üîç Tips y Buenas Pr√°cticas

### 1. Nombres de DAGs

- Usa nombres descriptivos y √∫nicos
- Usa snake_case: `mi_dag_ejemplo`
- Evita espacios y caracteres especiales

### 2. Nombres de Tareas

- Usa verbos de acci√≥n: `extraer_datos`, `transformar`, `cargar`
- S√© descriptivo pero conciso
- Usa snake_case

### 3. Manejo de Errores

```python
from airflow.exceptions import AirflowException

def mi_funcion():
    try:
        # Tu c√≥digo
        pass
    except Exception as e:
        error_msg = f"Error: {str(e)}"
        print(error_msg)
        raise AirflowException(error_msg)
```

### 4. Logging

```python
def mi_funcion():
    print("=" * 60)
    print("INICIANDO PROCESO")
    print("=" * 60)
    print(f"Fecha: {datetime.now()}")
    # Tu c√≥digo
    print("Proceso completado exitosamente")
```

### 5. XCom para Compartir Datos

```python
def tarea1(**context):
    resultado = "mi_valor"
    context['ti'].xcom_push(key='mi_key', value=resultado)

def tarea2(**context):
    valor = context['ti'].xcom_pull(key='mi_key', task_ids='tarea1')
    print(f"Valor recibido: {valor}")
```

### 6. DAGs Solo Manual

Para DAGs que solo deben ejecutarse manualmente:

```python
with DAG(
    'mi_dag_manual',
    schedule=None,  # IMPORTANTE: Sin schedule
    tags=['manual'],  # Tag para identificar
    # ... resto de configuraci√≥n
) as dag:
    # ...
```

## ‚ö†Ô∏è Notas Importantes

- Los archivos en `dags_local/` son editables con permisos de tu usuario
- La carpeta `dags/` (donde se despliegan) tiene permisos del contenedor Docker
- Siempre edita en `dags_local/`, nunca directamente en `dags/`
- Los cambios en `dags_local/` NO se reflejan autom√°ticamente, debes hacer `make deploy`
- Los DAGs se versionan en Git (est√°n en el repositorio)
- NO incluyas credenciales hardcodeadas, usa conexiones de Airflow

---

**√öltima actualizaci√≥n:** 2025-11-15
