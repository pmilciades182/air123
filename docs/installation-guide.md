# Gu√≠a R√°pida de Configuraci√≥n de Airflow

Esta es una gu√≠a r√°pida para configurar una nueva instancia de Airflow desde cero.

## Opci√≥n 1: Configuraci√≥n R√°pida con Script Autom√°tico ‚ö°

```bash
# 1. Generar claves de seguridad autom√°ticamente
./generate-keys.sh

# 2. Editar .env y ajustar la configuraci√≥n de PostgreSQL
nano .env

# 3. Crear la base de datos en PostgreSQL
psql -U postgres -h TU_HOST -p TU_PUERTO < setup-database.sql

# 4. Construir e iniciar Airflow
make build
make start

# 5. Obtener contrase√±a de acceso
make get-password

# 6. Acceder a la UI
# http://localhost:PUERTO (el puerto configurado en AIRFLOW_WEBSERVER_PORT)
```

## Opci√≥n 2: Configuraci√≥n Manual Paso a Paso üîß

### Paso 1: Crear archivo .env

Elige una de estas opciones seg√∫n tu entorno:

**Para desarrollo local:**
```bash
cp .env.example.local .env
```

**Para servidor/producci√≥n:**
```bash
cp .env.example .env
```

**Para segunda instancia:**
```bash
cp .env.instance2.example .env
```

### Paso 2: Generar Claves de Seguridad

**Generar AIRFLOW_FERNET_KEY:**
```bash
docker run --rm apache/airflow:3.1.3-python3.13 python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
```

**Generar AIRFLOW_JWT_SECRET:**
```bash
openssl rand -base64 16
```

### Paso 3: Editar .env

Abre el archivo `.env` y configura las siguientes variables:

```bash
# Identificaci√≥n √∫nica de la instancia
PROJECT_NAME=airflow1              # Cambia para cada instancia

# PostgreSQL
POSTGRES_HOST=192.168.24.109       # Tu servidor PostgreSQL
POSTGRES_PORT=5433                 # Puerto de PostgreSQL
POSTGRES_DB=airflow_db             # Nombre de la base de datos
POSTGRES_USER=airflow_user         # Usuario de PostgreSQL
POSTGRES_PASSWORD=airflow2025      # Contrase√±a de PostgreSQL

# Puerto del webserver
AIRFLOW_WEBSERVER_PORT=4000        # Puerto √∫nico por instancia

# Claves de seguridad (pegar las generadas en paso 2)
AIRFLOW_FERNET_KEY=TU_CLAVE_FERNET
AIRFLOW_JWT_SECRET=TU_JWT_SECRET
AIRFLOW_INTERNAL_API_SECRET=un-secret-unico

# Usuario web
AIRFLOW_WWW_USER_USERNAME=airflow
AIRFLOW_WWW_USER_PASSWORD=airflow
```

### Paso 4: Crear Base de Datos en PostgreSQL

**Conectarse a PostgreSQL:**
```bash
psql -U postgres -h 192.168.24.109 -p 5433
```

**Ejecutar comandos SQL:**
```sql
CREATE USER airflow_user WITH PASSWORD 'airflow2025';
CREATE DATABASE airflow_db OWNER airflow_user;
GRANT ALL PRIVILEGES ON DATABASE airflow_db TO airflow_user;
\q
```

O usar el script SQL:
```bash
psql -U postgres -h 192.168.24.109 -p 5433 < setup-database.sql
```

### Paso 5: Construir e Iniciar Airflow

```bash
# Construir las im√°genes Docker
make build

# Iniciar todos los servicios
make start

# Ver el estado
make status

# Ver logs
make logs
```

### Paso 6: Acceder a Airflow

**Obtener contrase√±a:**
```bash
make get-password
```

**Acceder a la UI:**
- URL: http://localhost:PUERTO (el puerto configurado en .env)
- Usuario: El configurado en `AIRFLOW_WWW_USER_USERNAME`
- Contrase√±a: La obtenida con `make get-password`

### Paso 7: Desplegar DAGs

```bash
# Desplegar todos los DAGs de dags_local/
make deploy

# O desplegar un DAG espec√≠fico
make deploy FILE=mi_dag.py
```

## Configuraci√≥n para M√∫ltiples Instancias

### Tabla de Valores para Cada Instancia

| Variable | Instancia 1 | Instancia 2 | Instancia 3 |
|----------|-------------|-------------|-------------|
| `PROJECT_NAME` | `airflow1` | `airflow2` | `airflow3` |
| `AIRFLOW_WEBSERVER_PORT` | `4000` | `4001` | `4002` |
| `POSTGRES_DB` | `airflow_db` | `airflow_db_instance2` | `airflow_db_instance3` |
| `POSTGRES_USER` | `airflow_user` | `airflow_user_instance2` | `airflow_user_instance3` |

### Crear Segunda Instancia

```bash
# 1. Copiar el proyecto completo
cp -r /home/paxo/airflow_develop /home/paxo/airflow_develop_2
cd /home/paxo/airflow_develop_2

# 2. Configurar .env con valores √∫nicos
cp .env.instance2.example .env
./generate-keys.sh  # Generar nuevas claves √∫nicas

# 3. Crear nueva base de datos en PostgreSQL
# (Ajustar los valores en setup-database.sql primero)

# 4. Iniciar
make build
make start
```

## Comandos √ötiles

```bash
# Ver ayuda (muestra la instancia actual)
make help

# Ver estado de contenedores
make status

# Ver logs en tiempo real
make logs

# Ver logs de un servicio espec√≠fico
make logs-webserver
make logs-scheduler

# Reiniciar todo
make restart

# Detener todo
make stop

# Limpiar todo (incluye vol√∫menes y base de datos local)
make clean

# Obtener contrase√±a
make get-password
```

## Verificaci√≥n de la Instalaci√≥n

**1. Verificar que todos los servicios est√©n corriendo:**
```bash
make status
```

Deber√≠as ver estos servicios `Up`:
- airflow-webserver
- airflow-scheduler
- airflow-triggerer
- airflow-dag-processor

**2. Verificar logs sin errores:**
```bash
make logs-scheduler | grep -i error
```

**3. Acceder a la UI y verificar:**
- Panel de salud (Health) - todos los componentes en verde
- DAGs - deber√≠a aparecer `ejemplo_dag`

## Soluci√≥n de Problemas Comunes

### Error: Puerto en uso
```bash
# Cambiar AIRFLOW_WEBSERVER_PORT en .env a otro puerto
nano .env
make restart
```

### Error: No puede conectar a PostgreSQL
```bash
# Verificar conectividad
telnet 192.168.24.109 5433

# Verificar credenciales en .env
cat .env | grep POSTGRES
```

### Error: Invalid auth token
```bash
# Verificar que las claves est√©n configuradas
cat .env | grep -E "(FERNET|JWT|SECRET)"

# Regenerar claves si es necesario
./generate-keys.sh
make restart
```

### DAGs no aparecen
```bash
# Verificar que el archivo est√© en dags/
ls -la dags/

# Redesplegar
make deploy

# Ver logs del dag-processor
docker-compose --project-name $(grep PROJECT_NAME .env | cut -d= -f2) logs airflow-dag-processor
```

## Archivos de Configuraci√≥n

| Archivo | Descripci√≥n |
|---------|-------------|
| `.env` | Configuraci√≥n de la instancia (NO versionar) |
| `.env.example` | Plantilla para servidor/producci√≥n |
| `.env.example.local` | Plantilla para desarrollo local |
| `.env.instance2.example` | Ejemplo para segunda instancia |
| `generate-keys.sh` | Script para generar claves autom√°ticamente |
| `setup-database.sql` | Script SQL para crear base de datos |
| `docker-compose.yml` | Configuraci√≥n de servicios Docker |
| `Makefile` | Comandos de gesti√≥n |

## Recursos Adicionales

- [README completo](README.md) - Documentaci√≥n completa del proyecto
- [Documentaci√≥n oficial de Airflow 3.x](https://airflow.apache.org/docs/apache-airflow/3.1.3/)
- [Gu√≠a de DAGs](https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html)
