# ==============================================================================
# CONFIGURACIÓN LOCAL DE AIRFLOW PARA DESARROLLO
# ==============================================================================
# Este archivo contiene valores de ejemplo para desarrollo local
# Copia este archivo a .env y ajusta según tus necesidades
#
# INSTRUCCIONES:
# 1. cp .env.example.local .env
# 2. Ajusta los valores según tu entorno
# 3. Genera las claves de seguridad (ver comandos abajo)
# 4. Crea la base de datos en PostgreSQL
# 5. make build && make start
# ==============================================================================

# ==============================================================================
# IDENTIFICACIÓN DE INSTANCIA
# ==============================================================================
# Nombre único del proyecto (usado para nombres de contenedores)
# Ejemplos: airflow_dev, airflow_local, mi_proyecto_airflow
PROJECT_NAME=airflow_local

# ==============================================================================
# CONFIGURACIÓN DE USUARIO Y PERMISOS
# ==============================================================================
# UID y GID del usuario de Airflow dentro del contenedor
# 50000 es el valor por defecto de Airflow
AIRFLOW_UID=50000
AIRFLOW_GID=0

# ==============================================================================
# CONFIGURACIÓN DE POSTGRESQL
# ==============================================================================
# Servidor PostgreSQL
# Para desarrollo local con PostgreSQL en el mismo servidor:
POSTGRES_HOST=localhost
# Si usas PostgreSQL en Docker, usa: POSTGRES_HOST=host.docker.internal

# Puerto de PostgreSQL
POSTGRES_PORT=5432

# Credenciales de base de datos
# IMPORTANTE: Cambia estos valores por los de tu instalación
POSTGRES_DB=airflow_local_db
POSTGRES_USER=airflow_local_user
POSTGRES_PASSWORD=airflow_local_pass_2025

# ==============================================================================
# CONFIGURACIÓN DE PUERTOS
# ==============================================================================
# Puerto donde se expondrá el webserver de Airflow
# Puedes cambiarlo si el puerto 8080 está en uso
AIRFLOW_WEBSERVER_PORT=8080

# ==============================================================================
# CLAVES DE SEGURIDAD
# ==============================================================================
# IMPORTANTE: Debes generar claves únicas para tu instalación
# NO uses estos valores de ejemplo en producción

# Clave Fernet para encriptación de conexiones y variables sensibles
# Generar con:
# docker run --rm apache/airflow:3.1.3-python3.13 python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
# O con Python local:
# python3 -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
AIRFLOW_FERNET_KEY=REEMPLAZAR_CON_CLAVE_GENERADA

# Secret para autenticación JWT entre componentes internos
# Generar con: openssl rand -base64 16
AIRFLOW_JWT_SECRET=REEMPLAZAR_CON_JWT_SECRET_GENERADO

# Secret para API interna (puede ser cualquier string único)
AIRFLOW_INTERNAL_API_SECRET=mi-secret-local-desarrollo-2025

# ==============================================================================
# CONFIGURACIÓN DE USUARIO WEB
# ==============================================================================
# Credenciales para acceder a la UI web de Airflow
AIRFLOW_WWW_USER_USERNAME=admin
AIRFLOW_WWW_USER_PASSWORD=admin123

# ==============================================================================
# CONFIGURACIÓN DE DIRECTORIOS
# ==============================================================================
# Directorio raíz del proyecto (normalmente el directorio actual)
AIRFLOW_PROJ_DIR=.

# ==============================================================================
# PAQUETES PYTHON ADICIONALES (OPCIONAL)
# ==============================================================================
# Lista de paquetes Python adicionales separados por espacios
# Ejemplo: _PIP_ADDITIONAL_REQUIREMENTS=pandas numpy requests boto3
_PIP_ADDITIONAL_REQUIREMENTS=

# ==============================================================================
# CONEXIONES SMTP
# ==============================================================================
# Conexión SMTP para envío de emails desde DAGs
# Formato: smtp://[usuario:password@]host:puerto/?from_email=email_origen
AIRFLOW_CONN_SMTP_IDESA=smtp://:@192.168.250.30:25/?from_email=airflow@idesa.com.py

# ==============================================================================
# CONEXIONES POSTGRESQL
# ==============================================================================
# Conexión PostgreSQL IDESA para consultas desde DAGs
# Formato: postgresql://usuario:password@host:puerto/database
# NOTA: Caracteres especiales en password deben ser URL-encoded (@ = %40, etc.)
AIRFLOW_CONN_POSTGRES_IDESA=postgresql://postgres:5PASzT0%40iB@192.168.24.109:5433/planos

# ==============================================================================
# CONEXIONES IBM i DB2 (AS/400)
# ==============================================================================
# Conexión IBM i DB2 para consultas desde DAGs
# Formato: odbc://usuario:password@host/?driver=nombre_driver&param1=valor1&param2=valor2
# NOTA: Espacios en nombres deben ser URL-encoded como +
AIRFLOW_CONN_IBMI_DEV=odbc://WEBUSR:idesa18@192.168.24.1/?driver=iSeries+Access+ODBC+Driver&DefaultLibraries=QGPL&ExtendedDynamic=1&AllowDataCompression=1&AllowUnsupportedChar=1&ForceTranslation=1&TrueAutoCommit=1

# ==============================================================================
# COMANDOS ÚTILES
# ==============================================================================
#
# 1. Generar AIRFLOW_FERNET_KEY:
#    docker run --rm apache/airflow:3.1.3-python3.13 python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
#
# 2. Generar AIRFLOW_JWT_SECRET:
#    openssl rand -base64 16
#
# 3. Crear base de datos en PostgreSQL:
#    psql -U postgres
#    CREATE USER airflow_local_user WITH PASSWORD 'airflow_local_pass_2025';
#    CREATE DATABASE airflow_local_db OWNER airflow_local_user;
#    GRANT ALL PRIVILEGES ON DATABASE airflow_local_db TO airflow_local_user;
#    \q
#
# 4. Construir e iniciar Airflow:
#    make build
#    make start
#
# 5. Acceder a la UI:
#    http://localhost:8080
#    Usuario: admin
#    Contraseña: admin123 (o usar 'make get-password')
#
# 6. Ver logs:
#    make logs
#
# 7. Ver estado:
#    make status
#
# 8. Desplegar DAGs:
#    make deploy
#
# 9. Detener todo:
#    make stop
#
# 10. Limpiar todo (incluye volúmenes):
#     make clean
#
# ==============================================================================
